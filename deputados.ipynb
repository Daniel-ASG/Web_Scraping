{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "deputados.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMOFaKEqLCnFDyFeaeiHztw",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Daniel-ASG/Web_Scraping/blob/main/deputados.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ynqqRjqovijq"
      },
      "source": [
        "# Obter os dados dentro de toda a página"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D0LruIbhHanK"
      },
      "source": [
        "import requests\r\n",
        "from urllib.request import urlopen\r\n",
        "from bs4 import BeautifulSoup\r\n",
        "import pandas as  pd\r\n",
        "from urllib.request import urlretrieve\r\n",
        "import os\r\n",
        "\r\n",
        "def trata_html(input):\r\n",
        "    return ' '.join(input.split()).replace('> <', '><')\r\n",
        "\r\n",
        "response = urlopen('https://www.camara.leg.br/deputados/quem-sao/resultado?search=&partido=&uf=&legislatura=56&sexo=')\r\n",
        "html = response.read().decode('utf-8')\r\n",
        "html = trata_html(html)\r\n",
        "soup = BeautifulSoup(html, 'html.parser')\r\n",
        "\r\n",
        "total_de_deputados = int(soup.find('div', {'class': 'busca-info__resultado busca-info__resultado--informado'}).getText().split(' ')[-2])\r\n",
        "pages = int(total_de_deputados/25) + 1\r\n",
        "\r\n",
        "url = []\r\n",
        "cards = []\r\n",
        "\r\n",
        "\r\n",
        "i=0\r\n",
        "for page in range(pages):\r\n",
        "    response = urlopen('https://www.camara.leg.br/deputados/quem-sao/resultado?search=&partido=&uf=&legislatura=56&sexo=&pagina=' + str(page+1))\r\n",
        "    html = response.read().decode('utf-8')\r\n",
        "    html = trata_html(html)\r\n",
        "    soup = BeautifulSoup(html, 'html.parser')\r\n",
        "\r\n",
        "    paginas = soup.findAll('li', {'class': 'lista-resultados__item'})\r\n",
        "\r\n",
        "    for pagina in paginas:\r\n",
        "        url.append('https://www.camara.leg.br' + pagina.a.get('href'))\r\n",
        "\r\n",
        "        response =  urlopen(url[i])\r\n",
        "        html = response.read().decode('utf-8')\r\n",
        "        html = trata_html(html)\r\n",
        "        ficha = BeautifulSoup(html, 'html.parser')\r\n",
        "\r\n",
        "        response =  urlopen(url[i]+'/biografia')\r\n",
        "        html = response.read().decode('utf-8')\r\n",
        "        html = trata_html(html)\r\n",
        "        bio = BeautifulSoup(html, 'html.parser')\r\n",
        "\r\n",
        "\r\n",
        "        # cria novo card para cada deputado\r\n",
        "        card = {}\r\n",
        "\r\n",
        "        infos_bio = bio.find('ul', {'class': 'informacoes-deputado'}).findAll('li')\r\n",
        "        n=0\r\n",
        "        for info in infos_bio:\r\n",
        "            if n>2:\r\n",
        "                card[info.getText().split(':')[0]] = info.getText().split(':')[1].strip()\r\n",
        "            n+=1\r\n",
        "\r\n",
        "        infos = ficha.find('ul', {'class': 'informacoes-deputado'}).findAll('li')\r\n",
        "        for info in infos:\r\n",
        "            card[info.getText().split(':')[0]] = info.getText().split(':')[1].strip()\r\n",
        "\r\n",
        "        card['Nome'] = ficha.find('h2', {'class': 'nome-deputado'}).getText()\r\n",
        "        card['Partido'] = ficha.find('span', {'class': 'foto-deputado__partido-estado'}).getText().split(' - ')[0]\r\n",
        "        card['Estado'] = ficha.find('span', {'class': 'foto-deputado__partido-estado'}).getText().split(' - ')[1]\r\n",
        "\r\n",
        "        if ficha.find('title').getText().strip().split(' ')[0] == 'Deputada':\r\n",
        "            card['Sexo'] = 'Feminino'\r\n",
        "        else:\r\n",
        "            card['Sexo'] = 'Masculino'\r\n",
        "        \r\n",
        "        # acrescenta o card deste deputado à lista cards\r\n",
        "        cards.append(card)\r\n",
        "\r\n",
        "\r\n",
        "        # dir = '/content/img/'\r\n",
        "        # if not os.path.exists(dir):\r\n",
        "        #     os.makedirs(dir)\r\n",
        "        # urlretrieve(soup.img.get('src'), '/content/img/' + '_'.join(card['Nome'].split(' ')) + '.jpg')\r\n",
        "        \r\n",
        "        i+=1\r\n",
        "\r\n",
        "dataset = pd.DataFrame(cards)\r\n",
        "dataset[['Nome', 'Nome Civil', 'Partido', 'Estado', 'Naturalidade', 'Sexo', 'Data de Nascimento', 'Profissões', 'Escolaridade', 'E-mail', 'Telefone', 'Endereço']]"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}